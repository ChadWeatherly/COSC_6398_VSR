{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6be0b271d4abd02",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Diffusion Model for Video Super Resolution\n",
    "\n",
    "Inspiration gathered from:\n",
    "\n",
    "https://github.com/CompVis/latent-diffusion\n",
    "\n",
    "https://ar5iv.labs.arxiv.org/html/2311.15908"
   ]
  },
  {
   "cell_type": "code",
   "id": "6840a1735dd2c511",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:42.890462Z",
     "start_time": "2024-04-28T23:26:42.887200Z"
    }
   },
   "source": [
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # provides functions that don't need to be in a computational graph, i.e. aren't part of a NN, usually for single-use\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
    "set('PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512')\n",
    "set('PYTORCH_ENABLE_MPS_FALLBACK=1')\n",
    "\n",
    "\"\"\"\n",
    "if matplotlib doesn't run, go into the envs/pytorch_vsr environment in anaconda3\n",
    "and delete all version of libiomp5md.dll , and it should work\n",
    "\"\"\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
    "# device = 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "1de92679892104e7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:42.924090Z",
     "start_time": "2024-04-28T23:26:42.921233Z"
    }
   },
   "source": [
    "torchvision.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3783a106bfa2d3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:42.939722Z",
     "start_time": "2024-04-28T23:26:42.937629Z"
    }
   },
   "source": [
    "# # datasets with _sharp are the correct/ground truth images\n",
    "# # datasets with _blur_bicubic are those that have been blurred and\n",
    "# # downsampled using bicubic interpolation\n",
    "# datasets = ['train_sharp', 'train_blur_bicubic', 'val_sharp', 'val_blur_bicubic']\n",
    "# for set in datasets:\n",
    "#     print(set)\n",
    "#     if not os.path.isfile(f\"REDS/{set}.zip\"):\n",
    "#         # print(\"Downloading\")\n",
    "#         cmdlet = f\"python download_REDS.py --{set}\"\n",
    "#         print(cmdlet)\n",
    "#         os.system(cmdlet)\n",
    "# # if not already downloaded, this will download all datasets (takes a while)\n",
    "# \n",
    "# # Set up data into dataset and dataloader\n",
    "# # It assumes the project file structure as downloaded from above\n",
    "# # Built based on docs: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "# class REDS(Dataset):\n",
    "#     def __init__(self, train=True, device='cuda'):\n",
    "#         self.device = device\n",
    "#         self.type = 'train' if train else 'test' \n",
    "#         if self.type == 'train':\n",
    "#             self.hr_dir = \"REDS/train_sharp/train/train_sharp\"\n",
    "#             self.lr_dir = \"REDS/train_blur_bicubic/train/train_blur_bicubic/X4\"\n",
    "#         else:\n",
    "#             self.hr_dir = \"REDS/val_sharp/val/val_sharp\"\n",
    "#             self.lr_dir = \"REDS/val_blur_bicubic/val/val_blur_bicubic/X4\"\n",
    "#             \n",
    "#     def __len__(self):\n",
    "#         return len(os.listdir(self.hr_dir)) # training size = 240 videos, testing size = 30 videos\n",
    "#             \n",
    "#     def __getitem__(self, idx):\n",
    "#         # each return gives a single HR frame with 5 corresponding LR frames\n",
    "#         # the middle LR frame (frame 3) will be the blurred/downsampled version of the HR frame\n",
    "#         # the 5 sequential LR frames will be chosen randomly from the given idx-video\n",
    "#         \n",
    "#         # Getting video sequence folder name\n",
    "#         if idx < 10:\n",
    "#             video = '00' + str(idx)\n",
    "#         elif idx < 100:\n",
    "#             video = '0' + str(idx)\n",
    "#         else:\n",
    "#             video = str(idx)\n",
    "#         # Getting random sequence of 5 LR frames from the video    \n",
    "#         num_video_frames = len(os.listdir(f\"{self.hr_dir}/000\"))\n",
    "#         rand_frame_id = np.random.randint(2, num_video_frames - 2)\n",
    "#         lr_frame_idx = []\n",
    "#         for i in range(-2, 3):\n",
    "#             id_int = rand_frame_id + i\n",
    "#             if id_int < 10:\n",
    "#                 id_str = '0000000' + str(id_int)\n",
    "#             elif id_int < 100:\n",
    "#                 id_str = '000000' + str(id_int)\n",
    "#             else:\n",
    "#                 id_str = '00000' + str(id_int)\n",
    "#             lr_frame_idx.append(id_str)\n",
    "#         # Actually reading in the images\n",
    "#         hr_frame = torchvision.io.read_image(f\"{self.hr_dir}/{video}/{lr_frame_idx[2]}.png\").to(self.device)\n",
    "#         lr_frames = []\n",
    "#         for v in lr_frame_idx:\n",
    "#             lr_frame = torchvision.io.read_image(f\"{self.lr_dir}/{video}/{v}.png\").to(self.device)\n",
    "#             lr_frames.append(lr_frame)\n",
    "#         lr_frames = torch.stack(lr_frames).permute(1, 0, 2, 3)\n",
    "#         # hr_frame is of size 3x720x1280 (CxHxW)\n",
    "#         # lr_imgs of of size 5x3x180x320 (TxCxHxW)\n",
    "#         # where C=channel, T=time (video sequence)\n",
    "#         return torch.tensor(lr_frames).float(), hr_frame.float()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "8859036c19a75c4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:43.183806Z",
     "start_time": "2024-04-28T23:26:42.950988Z"
    }
   },
   "source": [
    "# If using REDS\n",
    "# train_dataset = REDS(train=True, device=device)\n",
    "# test_dataset = REDS(train=False, device=device)\n",
    "\n",
    "# If using moving MNIST : http://www.cs.toronto.edu/~nitish/unsupervised_video/\n",
    "# This will download all the data\n",
    "data = torchvision.datasets.MovingMNIST(root='./', split=None,\n",
    "                                        split_ratio=10, download=True) # data has 10,000 videos (each video is a sequence of 20 frames)\n",
    "train_data = data[0:8000].to('cpu')      # 80% for train\n",
    "test_data = data[8000:10001].to('cpu')    # 20% for test\n",
    "\n",
    "def transform_image(image):\n",
    "    # Performs downsampling and then blurring\n",
    "    image = torchvision.transforms.functional.resize(image, (32, 32))\n",
    "    gb = torchvision.transforms.GaussianBlur(kernel_size=(3,3))\n",
    "    image = gb(image)\n",
    "    return image\n",
    "    \n",
    "def get_sample(data, idx):\n",
    "    \"\"\"\n",
    "    Given a dataset (train/test) and a sample idx, a random sequence\n",
    "    of 5 LR frames is computed\n",
    "    \"\"\"\n",
    "    num_video_frames = data[idx].size()[0]\n",
    "    rand_frame_idx = np.random.randint(2, num_video_frames - 2)\n",
    "    # Get HR frame\n",
    "    hr_frame = data[idx][rand_frame_idx].to(device)\n",
    "    # Get LR frames\n",
    "    lr_frames = [data[idx][k] for k in range(rand_frame_idx-2, rand_frame_idx+3)]\n",
    "    lr_frames = [transform_image(frame) for frame in lr_frames]\n",
    "    lr_frames = torch.stack(lr_frames, dim=0).to(device) # permuted to have channel first\n",
    "    return lr_frames, hr_frame\n",
    "\n",
    "lr_frames, hr_frame = get_sample(data, 0)\n",
    "print('Comparing the 5 low-res images to the one high-res one')\n",
    "for f in lr_frames:\n",
    "    pil_fr = torchvision.transforms.ToPILImage()(f)\n",
    "    display(pil_fr)\n",
    "display(torchvision.transforms.ToPILImage()(hr_frame))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the 5 low-res images to the one high-res one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABJUlEQVR4nOWRT0/CQBDFZxdKlxYsjSlpBIIY9KJRP4Hf/2z1ABprqH8CiizF2rLtdj0Y467pnjw6p8nbX96bmQX4ayG5bxHIEU9zGahLvTk+chmbTeY6wPCPexwFKy0g6APf6Xcd0AHpbeweNkqMhAbguTU6GWLLYJKIZTvSHQxszOTNFAcoaLSXvy5LLbAOHm1/Fil3UCLymJso/tBuAQCwSFbObs0sNrT4EpD67o4HDgZK8qdgXekQv/R75lIMhbiujuBF9pYtHMzoVjPD+yRMOmeb+0laDTSttut5JLyai0qADA/G/j67nIbfCSrQGF2ce1l7ma4zqARwx0XTm6ZXk35cAcrNdB7d1U8NrAFY+CySrU0M+qP9uiQAALQwTyrk/12f06Nuezk2SmMAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABJ0lEQVR4nGNgoDlgRGJyMv9lYvj2D1UBC4LJOUXriuLfpKf/cSlgFJYRZeE22/wbl4LvGWwfBbYwMjDgUvDvJSeLsuB7NDcgu1dk4YlHX/s5cZrAwCr99BfbiT84TWBg4hFq2i6ALojE/vfll/mtn3gUMDBwiP38j6YA2Q0MjCyXF/xiYGBmYmBk+g81CtXbTBw//jHy6Cn9Z5X+NvUnFgUMDAyMIp2u/w/vcVLw/IJpBQMDAwOzLlPdoVfy+TN+ocvAXcXFxiK8ZI0ANkcyMDAwMLEwcKnHsRZ8hFmJLq8ZqmzGfyL1Dcy7qOHAwCgy4Rcn23HZX+jBAQNc854+nm9o9ECbCYcCZvMkbR4m/lOeGG6Dq2BjYmBgdTNgxqUAAlgIyA8/AADLF0jGWPTiZAAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABMklEQVR4nNWRS0/CQBSFz0ynFCmIRtsGoyYqcWETDbJy4493584HPgghIZYQ5VXaYoHSDm6o4pSujWd1k/nmnJx7gb8XiQemG5k5H3V9AWDxkDWv9dns8aaVBhCWzamb4XMqMKv7ql6NGNKA4J3rmryhsDAFgHpWNQ8aGUkA6E8fChKMPZ4WgXGtPz2uW4LBioPfatjuh71IdQBysj8MlnmEgnMRCJqdNw6QnL6bjVjYa08EwH2Ay4Giean5wy3pqS8CkwkAIF/SMJprSiMSI+Kktmv7J45T/wRWrvktouTV/P4p7u/ctQ50xyjtlQud25qXqAkAZLtSOSwYXrO13IgIyEdXF5HVY5G03JgIUMl5sV75OStiPRBaAe0OFFaYxpnJFguAaYo3SLz8omjy53/WF4rnbvfYgnDAAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABGUlEQVR4nGNgGAKAEUZzMP9lYvj2H0MBC5TmmKZ1WfF//DMMFTAFjCIyYsw85pv+4FLwPZXtg8B2RnRphIL/rzhYVATfYboB7liRRacef53AgdMEBhaZxz/Yjv/FaQIDI7dg005+3G5g+P+VweL6T0wFTAgmhzhCnpGFlY2NgxnZBAZGlsvzf0HZrBJW/3lY1JdcQnETIyfMOJaAi8/OtkY+iGFFNoHh/3cYi9Vl+9ZLzHlP9mCEK9wsDhYOj8v+rDjkGVg5eOSijkRwMDAgohsZcIUYGGv+S9r3A82bMMARGPaF//wHSVyhymx77+nZDPFpkzkhPsJQ8PdC+6MznxkueGGzHeIHVhYGBkb+NDZcCqDKCMgPLQAAeshJzdR6C/QAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABM0lEQVR4nN3SS0/CQBAH8Gm7fawUELFRiaA92EBCYjzoyYvxU3vyG2h9JMQHIhQjaCJ94S4ttB7Aiun2bvxfNpn8MjPZXYD/EA4AAND6phhGzhtJAwQAAHLztEzDm/NuFuBFRVWLs+tMQFtjrB1NEWOHeS0cxpomYUmYZQDINQ8btUcFpQG/OASA0PWirBHgXQ2cRsuapsGiA+m2XX9gx5kdALA8HgVLdYyRgKhNEhC0X3vJClxeN4okzH9cPifANTknAdLusTGxeH348DOC0qXBgkjv+34dRg6wLg8gtOxgtpfrX7yzAY9zhdJWZWLeUTZYMwx9p9Q7M11ggsLBSU3ihcj3YjZQqxv0trNdXpUJGwRPU6/9Ut+PJPL95X4HrYiURJXqZ8dng3lEJaaMx/uT+QL5KXIjuez5BgAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAABsUlEQVR4nO2UsUtCQRzHv0oSIrT0mgoagnwiEfRoKNCa2oKU+hOSVocodLOW/gKhFmloSoSGHMOpodpSp8ggsqOW0Gq539lgWdDz3Xv3loL3mY673/fzuzvuPcDD468y0WG5jcH1s9zZsJrggL6Iyov9lqubcsGAydzLe+AJALSAPG/OQhIAcEUFtR2gAgAIDdppZnEHixE8uREMTQAncoHpEYLTa2Fos8D2w41cYcJk7yHsS2ut30FTLjA9wusp7gs4iDYTl1KBBed0ZKOq/xHmp1BzJZgLouRKsGwjbSmwSV/B2KhL8wLRlp3t+fot+Hdae53f0+N41lF/syH4RXwlVvfpd4iEfaVV26nvzkVBggQ1MmnWIef5COPEieeXNBiccs4FF4Iame6Prkht3bkgkV/SuqMk8Yzz/DcGE8xNHhXOZlzEQ0XBIurxeKqq2n/cMHZrJEgcq7XOMk68yomTWv80XcSMXUHtlsgrCRiPJYnTtX5Ijwpxg4mqIMGyQErQiHNBpfsVzADQiKecC0bKjcPU5zsWpCAAtN7omJdVBD92c+tSAF2T13h4ePxTPgBqqKjmqs3qIwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "566a961439deb8ba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:43.860024Z",
     "start_time": "2024-04-28T23:26:43.184774Z"
    }
   },
   "source": [
    "# Set up loss functions\n",
    "\n",
    "# perceptual_loss\n",
    "vgg = torchvision.models.vgg19(weights='VGG19_Weights.IMAGENET1K_V1').features # removes final classification layer as we don't need it\n",
    "vgg.to(device)\n",
    "vgg.eval() # sets the model to evaluation mode, to not update weights/parameters\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False # don't calculate gradients after forward passes, reduces computation\n",
    "    \n",
    "# A hook function can be used on any nn.module(), like any layer of a neural net\n",
    "# Depending on whether it's a backwards hook (backprop) or forward hook (forward pass),\n",
    "# the inputs and outputs of that nn.module can be accessed for that operation\n",
    "# It's like an event, that each time it happens, the inputs/outputs of that module are saved and then used by vgg_hook\n",
    "vgg_activations = {3:torch.tensor(0),\n",
    "                   8:torch.tensor(0),\n",
    "                   17:torch.tensor(0),\n",
    "                   26:torch.tensor(0),\n",
    "                   35:torch.tensor(0)}\n",
    "def vgg_hook(module, input, output):   \n",
    "    # Get activations at several layers\n",
    "    for layer in [3, 8, 17, 26, 35]: # each of the layers we want\n",
    "        if module == vgg[layer]: \n",
    "            vgg_activations[layer] = output\n",
    "    \n",
    "for layer in [3, 8, 17, 26, 35]:\n",
    "    vgg[layer].register_forward_hook(vgg_hook)\n",
    "\n",
    "def perceptual_loss(generated_img, target_img): # we want a lower value\n",
    "    # with torch.no_grad():\n",
    "    _ = vgg(generated_img)\n",
    "    generated_activations = vgg_activations.copy()\n",
    "    _ = vgg(target_img)\n",
    "    target_activations = vgg_activations.copy()\n",
    "    \n",
    "    # calculate F1 (mean absolute loss (MAE)) for each activation layer\n",
    "    mae_loss = []\n",
    "    for layer in [3, 8, 17, 26, 35]:\n",
    "        mae = F.l1_loss(generated_activations[layer],\n",
    "                        target_activations[layer])\n",
    "        mae_loss.append(mae)\n",
    "        \n",
    "    return sum(mae_loss)\n",
    "\n",
    "# Test if perceptual loss works\n",
    "lr_imgs1, hr_img1 = get_sample(train_data, 20)\n",
    "lr_imgs2, hr_img2 = get_sample(train_data, 30)\n",
    "\n",
    "\n",
    "print(f\"Differing video sequences: {perceptual_loss(hr_img1.expand(3,-1,-1).float(), hr_img2.expand(3,-1,-1).float())}\")\n",
    "print(f\"Same frame: {perceptual_loss(hr_img2.expand(3,-1,-1).float(), hr_img2.expand(3,-1,-1).float())}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differing video sequences: 165.8286895751953\n",
      "Same frame: 0.0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "359655adb76c665e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:43.862707Z",
     "start_time": "2024-04-28T23:26:43.860922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters for training/testing\n",
    "new_model = False\n",
    "num_epochs = 35\n",
    "# pq batches take ~ 1 secs, so 1 epoch ~ 1.5 minutes\n",
    "# mse batches take ~ 1 secs, so 1 epoch ~ 1.5 minutes\n",
    "\n",
    "# To run an entire epoch through takes ~ 3 minutes for both models\n",
    "skip_graphs = True\n",
    "learning_rate = 0.000001\n",
    "batch_size = 100\n",
    "train = False      # if false, then the models will initialize with best weights (for inference/testing)"
   ],
   "id": "4799eeebab0107b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.070476Z",
     "start_time": "2024-04-28T23:26:43.863911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# Can be either 'mse' or 'pq'\n",
    "loss_function = 'pq'\n",
    "path = f'saved_models/recon_model_{loss_function}.pt'\n",
    "# Initialize Model architecture\n",
    "pq_recon_model = reconstructor(device=device).to(device)\n",
    "if new_model:\n",
    "    # Train/Test \n",
    "    # Mean Square Error/Perceptual Quality\n",
    "    train_mse_loss = []\n",
    "    train_pq_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_pq_loss = []\n",
    "    best_val_loss = float('inf')\n",
    "else:\n",
    "    # Get dictionary of info\n",
    "    old_model = torch.load(path, map_location=device)\n",
    "    # load model with previous weights/parameters\n",
    "    pq_recon_model.load_state_dict(old_model[0])\n",
    "    # update previous lists of loss\n",
    "    if loss_function == 'mse':\n",
    "        train_mse_loss = old_model[1]\n",
    "        test_mse_loss = old_model[2]\n",
    "    else:\n",
    "        train_pq_loss = old_model[1]\n",
    "        test_pq_loss = old_model[2]\n",
    "    best_val_loss = old_model[3]\n",
    "    \n",
    "if train:\n",
    "    start_time = time.time()\n",
    "    prev_batch_time = start_time\n",
    "    mse = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=pq_recon_model.parameters(),\n",
    "                                 lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        pq_recon_model.train()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(train_data)):\n",
    "            # Get data sample\n",
    "            lr_imgs, hr_img = get_sample(train_data, i)\n",
    "            lr_imgs = lr_imgs.float()\n",
    "            hr_img = hr_img.float().to(device)\n",
    "            # Do prediction\n",
    "            hr_pred = pq_recon_model(lr_imgs)\n",
    "            # calculate loss\n",
    "            if loss_function == 'mse':\n",
    "                loss = mse(hr_pred, \n",
    "                           hr_img)\n",
    "            else:\n",
    "                loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                       hr_img.expand(3,-1,-1))\n",
    "            # propagate loss through weights to find gradients\n",
    "            # and also adds gradients up\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            epoch_running_loss += loss.item()\n",
    "            del lr_imgs, hr_img, hr_pred\n",
    "            \n",
    "            if i % batch_size == 0 and i != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                avg_batch_loss = running_loss / batch_size\n",
    "                running_loss = 0\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                print(f'Batch: {int((i+1)/batch_size)} / {int(len(train_data)/batch_size)}')\n",
    "                print(f'Avg. Training Loss: {avg_batch_loss:.4f}')\n",
    "                # print(f'W-values: {pq_recon_model.w}')\n",
    "                # for name, param in pq_recon_model.named_parameters():\n",
    "                #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                #         print(param.data[0:5])\n",
    "                # Calculate batch training time   \n",
    "                curr_time = time.time()\n",
    "                time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                minutes, seconds = divmod(time_diff, 60)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'Training Time:')\n",
    "                print(f'{minutes} minutes:{seconds} seconds')\n",
    "                print()\n",
    "                prev_batch_time = curr_time\n",
    "                \n",
    "        avg_epoch_loss = epoch_running_loss / len(train_data)\n",
    "        if loss_function == 'mse':\n",
    "            train_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            train_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Training Loss: {avg_epoch_loss:.4f}')\n",
    "            \n",
    "        # Testing\n",
    "        pq_recon_model.eval()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(test_data)):\n",
    "            with torch.no_grad():\n",
    "                # Get data sample\n",
    "                lr_imgs, hr_img = get_sample(test_data, i)\n",
    "                hr_img = hr_img.float().to(device)\n",
    "                # Do prediction\n",
    "                hr_pred = pq_recon_model(lr_imgs)\n",
    "                hr_pred.requires_grad = True\n",
    "                # calculate loss\n",
    "                if loss_function == 'mse':\n",
    "                    loss = mse(hr_pred, \n",
    "                               hr_img)\n",
    "                else:\n",
    "                    loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                           hr_img.expand(3,-1,-1))\n",
    "                running_loss += loss.item()\n",
    "                epoch_running_loss += loss.item()\n",
    "                del lr_imgs, hr_img, hr_pred\n",
    "                \n",
    "                if i%batch_size == 0 and i != 0:\n",
    "                    avg_batch_loss = running_loss / batch_size\n",
    "                    running_loss = 0\n",
    "                    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                    print(f'Batch: {int((i+1)/batch_size)} / {int(len(test_data)/batch_size)}')\n",
    "                    print(f'Avg. Testing Loss: {avg_batch_loss:.4f}')\n",
    "                    # print(f'W-values: {pq_recon_model.w}')\n",
    "                    # for name, param in pq_recon_model.named_parameters():\n",
    "                    #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                    #         print(param.data[0:5])\n",
    "                    # Calculate batch training time   \n",
    "                    curr_time = time.time()\n",
    "                    time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                    minutes, seconds = divmod(time_diff, 60)\n",
    "                    minutes = int(minutes)\n",
    "                    seconds = int(seconds)\n",
    "                    print(f'Testing Time:')\n",
    "                    print(f'{minutes} minutes:{seconds} seconds')\n",
    "                    print()\n",
    "                    prev_batch_time = curr_time\n",
    "                    \n",
    "        avg_epoch_loss = epoch_running_loss / len(test_data)\n",
    "        if loss_function == 'mse':\n",
    "            test_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            test_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Testing Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # Capture results\n",
    "        if avg_epoch_loss < best_val_loss:\n",
    "            # print(avg_running_loss, best_val_loss)\n",
    "            best_val_loss = avg_epoch_loss\n",
    "            save_dict = dict()\n",
    "            save_dict[0] = pq_recon_model.state_dict()\n",
    "            if loss_function == 'mse':\n",
    "                save_dict[1] = train_mse_loss\n",
    "                save_dict[2] = test_mse_loss\n",
    "            else:\n",
    "                save_dict[1] = train_pq_loss\n",
    "                save_dict[2] = test_pq_loss\n",
    "            save_dict[3] = best_val_loss\n",
    "            torch.save(save_dict, path)\n",
    "            \n",
    "        # Calculate epoch training/testing time\n",
    "        if epoch==0:\n",
    "            curr_time = time.time()\n",
    "            prev_time = start_time\n",
    "        else:\n",
    "            prev_time = curr_time\n",
    "            curr_time = time.time()\n",
    "        time_diff = (curr_time - prev_time) # in seconds\n",
    "        minutes, seconds = divmod(time_diff, 60)\n",
    "        minutes = int(minutes)\n",
    "        seconds = int(seconds)\n",
    "        \n",
    "        print(f'Epoch Time:')\n",
    "        print(f'{minutes} minutes:{seconds} seconds')\n",
    "        print()\n",
    "        print(*\"====================\")\n",
    "        print()"
   ],
   "id": "8bcebbe8401c70a4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.073243Z",
     "start_time": "2024-04-28T23:26:44.071167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not skip_graphs:\n",
    "    # Plotting avg. training and testing loss for PQ-trained model\n",
    "    plt.plot(train_pq_loss)\n",
    "    plt.plot(test_pq_loss)\n",
    "    plt.title(\"Pereceptual Loss\")\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    \n",
    "    lr_imgs, hr_img = get_sample(test_data, 100)\n",
    "    hr_pred = pq_recon_model(lr_imgs)\n",
    "    \n",
    "    # mse_loss = mse(hr_pred, hr_img)\n",
    "    # perceptual_loss = perceptual_loss(hr_pred, hr_img)\n",
    "    # print(f'MSE Loss: {mse_loss:.4f}')\n",
    "    # print(f'Perceptual Loss: {perceptual_loss:.4f}')\n",
    "    \n",
    "    display(torchvision.transforms.ToPILImage()(hr_img))\n",
    "    display(torchvision.transforms.ToPILImage()(hr_pred))"
   ],
   "id": "c647af77cc73aacd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.121420Z",
     "start_time": "2024-04-28T23:26:44.073854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# Can be either 'mse' or 'pq'\n",
    "loss_function = 'mse'\n",
    "path = f'saved_models/recon_model_{loss_function}.pt'\n",
    "# Initialize Model architecture\n",
    "mse_recon_model = reconstructor(device=device).to(device)\n",
    "if new_model:\n",
    "    # Train/Test \n",
    "    # Mean Square Error/Perceptual Quality\n",
    "    train_mse_loss = []\n",
    "    train_pq_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_pq_loss = []\n",
    "    best_val_loss = float('inf')\n",
    "else:\n",
    "    # Get dictionary of info\n",
    "    old_model = torch.load(path, map_location=device)\n",
    "    # load model with previous weights/parameters\n",
    "    mse_recon_model.load_state_dict(old_model[0])\n",
    "    # update previous lists of loss\n",
    "    if loss_function == 'mse':\n",
    "        train_mse_loss = old_model[1]\n",
    "        test_mse_loss = old_model[2]\n",
    "    else:\n",
    "        train_pq_loss = old_model[1]\n",
    "        test_pq_loss = old_model[2]\n",
    "    best_val_loss = old_model[3]\n",
    "    \n",
    "if train:\n",
    "    start_time = time.time()\n",
    "    prev_batch_time = start_time\n",
    "    mse = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=mse_recon_model.parameters(),\n",
    "                                 lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        mse_recon_model.train()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(train_data)):\n",
    "            # Get data sample\n",
    "            lr_imgs, hr_img = get_sample(train_data, i)\n",
    "            hr_img = hr_img.float().to(device)\n",
    "            # Do prediction\n",
    "            hr_pred = mse_recon_model(lr_imgs)\n",
    "            # calculate loss\n",
    "            if loss_function == 'mse':\n",
    "                loss = mse(hr_pred, \n",
    "                           hr_img)\n",
    "            else:\n",
    "                loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                       hr_img.expand(3,-1,-1))\n",
    "            # propagate loss through weights to find gradients\n",
    "            # and also adds gradients up\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            epoch_running_loss += loss.item()\n",
    "            del lr_imgs, hr_img, hr_pred\n",
    "            \n",
    "            if i % batch_size == 0 and i != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                avg_batch_loss = running_loss / batch_size\n",
    "                running_loss = 0\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                print(f'Batch: {int((i+1)/batch_size)} / {int(len(train_data)/batch_size)}')\n",
    "                print(f'Avg. Training Loss: {avg_batch_loss:.4f}')\n",
    "                # print(f'W-values: {mse_recon_model.w}')\n",
    "                # for name, param in mse_recon_model.named_parameters():\n",
    "                #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                #         print(param.data[0:5])\n",
    "                # Calculate batch training time   \n",
    "                curr_time = time.time()\n",
    "                time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                minutes, seconds = divmod(time_diff, 60)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'Training Time:')\n",
    "                print(f'{minutes} minutes:{seconds} seconds')\n",
    "                print()\n",
    "                prev_batch_time = curr_time\n",
    "                \n",
    "        avg_epoch_loss = epoch_running_loss / len(train_data)\n",
    "        if loss_function == 'mse':\n",
    "            train_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            train_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Training Loss: {avg_epoch_loss:.4f}')\n",
    "            \n",
    "        # Testing\n",
    "        mse_recon_model.eval()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(test_data)):\n",
    "            with torch.no_grad():\n",
    "                # Get data sample\n",
    "                lr_imgs, hr_img = get_sample(test_data, i)\n",
    "                hr_img = hr_img.float().to(device)\n",
    "                # Do prediction\n",
    "                hr_pred = mse_recon_model(lr_imgs)\n",
    "                hr_pred.requires_grad = True\n",
    "                # calculate loss\n",
    "                if loss_function == 'mse':\n",
    "                    loss = mse(hr_pred, \n",
    "                               hr_img)\n",
    "                else:\n",
    "                    loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                           hr_img.expand(3,-1,-1))\n",
    "                running_loss += loss.item()\n",
    "                epoch_running_loss += loss.item()\n",
    "                del lr_imgs, hr_img, hr_pred\n",
    "                \n",
    "                if i%batch_size == 0 and i != 0:\n",
    "                    avg_batch_loss = running_loss / batch_size\n",
    "                    running_loss = 0\n",
    "                    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                    print(f'Batch: {int((i+1)/batch_size)} / {int(len(test_data)/batch_size)}')\n",
    "                    print(f'Avg. Testing Loss: {avg_batch_loss:.4f}')\n",
    "                    # print(f'W-values: {mse_recon_model.w}')\n",
    "                    # for name, param in mse_recon_model.named_parameters():\n",
    "                    #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                    #         print(param.data[0:5])\n",
    "                    # Calculate batch training time   \n",
    "                    curr_time = time.time()\n",
    "                    time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                    minutes, seconds = divmod(time_diff, 60)\n",
    "                    minutes = int(minutes)\n",
    "                    seconds = int(seconds)\n",
    "                    print(f'Testing Time:')\n",
    "                    print(f'{minutes} minutes:{seconds} seconds')\n",
    "                    print()\n",
    "                    prev_batch_time = curr_time\n",
    "                    \n",
    "        avg_epoch_loss = epoch_running_loss / len(test_data)\n",
    "        if loss_function == 'mse':\n",
    "            test_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            test_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Testing Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # Capture results\n",
    "        if avg_epoch_loss < best_val_loss:\n",
    "            # print(avg_running_loss, best_val_loss)\n",
    "            best_val_loss = avg_epoch_loss\n",
    "            save_dict = dict()\n",
    "            save_dict[0] = mse_recon_model.state_dict()\n",
    "            if loss_function == 'mse':\n",
    "                save_dict[1] = train_mse_loss\n",
    "                save_dict[2] = test_mse_loss\n",
    "            else:\n",
    "                save_dict[1] = train_pq_loss\n",
    "                save_dict[2] = test_pq_loss\n",
    "            save_dict[3] = best_val_loss\n",
    "            torch.save(save_dict, path)\n",
    "            \n",
    "        # Calculate epoch training/testing time\n",
    "        if epoch==0:\n",
    "            curr_time = time.time()\n",
    "            prev_time = start_time\n",
    "        else:\n",
    "            prev_time = curr_time\n",
    "            curr_time = time.time()\n",
    "        time_diff = (curr_time - prev_time) # in seconds\n",
    "        minutes, seconds = divmod(time_diff, 60)\n",
    "        minutes = int(minutes)\n",
    "        seconds = int(seconds)\n",
    "        \n",
    "        print(f'Epoch Time:')\n",
    "        print(f'{minutes} minutes:{seconds} seconds')\n",
    "        print()\n",
    "        print(*\"====================\")\n",
    "        print()"
   ],
   "id": "3825108fab352e76",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.124380Z",
     "start_time": "2024-04-28T23:26:44.122113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not skip_graphs:\n",
    "    # Plotting avg. training and testing loss for MSE-trained model\n",
    "    plt.plot(train_mse_loss)\n",
    "    plt.plot(test_mse_loss)\n",
    "    plt.title(\"MSE Loss\")\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    \n",
    "    lr_imgs, hr_img = get_sample(test_data, 25)\n",
    "    hr_pred = mse_recon_model(lr_imgs)\n",
    "    \n",
    "    # mse_loss = mse(hr_pred, hr_img)\n",
    "    # perceptual_loss = perceptual_loss(hr_pred, hr_img)\n",
    "    # print(f'MSE Loss: {mse_loss:.4f}')\n",
    "    # print(f'Perceptual Loss: {perceptual_loss:.4f}')\n",
    "    \n",
    "    display(torchvision.transforms.ToPILImage()(hr_img))\n",
    "    display(torchvision.transforms.ToPILImage()(hr_pred))"
   ],
   "id": "6d645f1db2480780",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.126751Z",
     "start_time": "2024-04-28T23:26:44.124918Z"
    }
   },
   "cell_type": "code",
   "source": "data[20].shape",
   "id": "8aacfba101cb6d60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:27:56.982902Z",
     "start_time": "2024-04-28T23:27:56.758388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show how predictions varied\n",
    "pq_recon_model.eval()\n",
    "mse_recon_model.eval()\n",
    "\n",
    "fig, axes = plt.subplots(5, 3)\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        axes[i,j].axis('off')\n",
    "axes[0,0].title.set_text('Ground Truth')\n",
    "axes[0,1].title.set_text('PQ Predicted')\n",
    "axes[0,2].title.set_text('MSE Predicted')\n",
    "for k in range(5): # Random inference values\n",
    "    with torch.no_grad():\n",
    "        lr_imgs, hr_img = get_sample(data, k)\n",
    "        hr_img = hr_img.squeeze().to('cpu').numpy()\n",
    "        hr_pred_pq = pq_recon_model(lr_imgs)\n",
    "        hr_pred_pq = hr_pred_pq.squeeze().to('cpu').numpy()\n",
    "        hr_pred_mse = mse_recon_model(lr_imgs)\n",
    "        hr_pred_mse = hr_pred_mse.squeeze().to('cpu').numpy()\n",
    "        axes[k,0].imshow(255-hr_img)\n",
    "        axes[k,1].imshow(255-hr_pred_pq)\n",
    "        axes[k,2].imshow(255-hr_pred_mse)\n",
    "        \n",
    "plt.savefig('report/figures/predictions.png')\n",
    "plt.show()"
   ],
   "id": "cbbe22d309c71640",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 15 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.415228Z",
     "start_time": "2024-04-28T23:26:44.413148Z"
    }
   },
   "cell_type": "code",
   "source": "axes",
   "id": "802b6e3043395ad6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'Ground Truth'}>,\n",
       "        <Axes: title={'center': 'PQ Predicted'}>,\n",
       "        <Axes: title={'center': 'MSE Predicted'}>],\n",
       "       [<Axes: >, <Axes: >, <Axes: >],\n",
       "       [<Axes: >, <Axes: >, <Axes: >],\n",
       "       [<Axes: >, <Axes: >, <Axes: >],\n",
       "       [<Axes: >, <Axes: >, <Axes: >]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.417128Z",
     "start_time": "2024-04-28T23:26:44.415758Z"
    }
   },
   "cell_type": "code",
   "source": "# Create GIFs",
   "id": "cfe0229bc2dc69dc",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.419608Z",
     "start_time": "2024-04-28T23:26:44.417622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not skip_graphs:\n",
    "    idx = np.random.randint(0, 10000)\n",
    "    \n",
    "    lr_frames, hr_frame = get_sample(data, idx)\n",
    "    print('Comparing the 5 low-res images to the one high-res one')\n",
    "    for j in range(len(lr_frames)):\n",
    "        f = lr_frames[j]\n",
    "        pil_fr = torchvision.transforms.ToPILImage()(f)\n",
    "        pil_fr.save(f'report/figures/Samples/{idx}_{j}_lr.png')\n",
    "        display(pil_fr)\n",
    "    pil_hr = torchvision.transforms.ToPILImage()(hr_frame)\n",
    "    pil_hr.save(f'report/figures/Samples/{idx}_hr.png')\n",
    "    display(pil_hr)"
   ],
   "id": "fe98de09f7cc2882",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.424852Z",
     "start_time": "2024-04-28T23:26:44.420310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # torch.cuda.empty_cache()\n",
    "# # Can be either 'mse' or 'pq'\n",
    "# loss_function = 'pq'\n",
    "# path = f'saved_models/diff_model_{loss_function}.pt'\n",
    "# # Initialize Model architecture\n",
    "# pq_diff_model = diffusion_vsr(s=torch.tensor(0.0008), \n",
    "#                            train_T=torch.tensor(1000), \n",
    "#                            infer_T=torch.tensor(1000),\n",
    "#                               device=device).to(device)\n",
    "# if new_model:\n",
    "#     # Train/Test \n",
    "#     # Mean Square Error/Perceptual Quality\n",
    "#     train_mse_loss = []\n",
    "#     train_pq_loss = []\n",
    "#     test_mse_loss = []\n",
    "#     test_pq_loss = []\n",
    "#     best_val_loss = float('inf')\n",
    "# else:\n",
    "#     # Get dictionary of info\n",
    "#     old_model = torch.load(path, map_location=device)\n",
    "#     # load model with previous weights/parameters\n",
    "#     pq_diff_model.load_state_dict(old_model[0])\n",
    "#     # update previous lists of loss\n",
    "#     if loss_function == 'mse':\n",
    "#         train_mse_loss = old_model[1]\n",
    "#         test_mse_loss = old_model[2]\n",
    "#     else:\n",
    "#         train_pq_loss = old_model[1]\n",
    "#         test_pq_loss = old_model[2]\n",
    "#     best_val_loss = old_model[3]\n",
    "#     \n",
    "# if train:\n",
    "#     start_time = time.time()\n",
    "#     mse = nn.MSELoss()\n",
    "#     optimizer = torch.optim.Adam(params=pq_diff_model.parameters(),\n",
    "#                                  lr=learning_rate)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "#         # Training\n",
    "#         pq_diff_model.train()\n",
    "#         pq_diff_model.calc_train_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(train_data)):\n",
    "#             lr_imgs, hr_img = get_sample(train_data, i)\n",
    "#             # random t-step to predict\n",
    "#             t = torch.randint(low=0, high=1000, size=(1,)).to(device)\n",
    "#             # hr_img after t steps of noise addition\n",
    "#             hr_t = pq_diff_model.add_noise(hr_img, t)\n",
    "#             # hr_img after t-1 steps of noise addition\n",
    "#             # This is what we want the model to predict (bc we want the reverse process)\n",
    "#             hr_tmin1 = pq_diff_model.add_noise(hr_img, t-1)\n",
    "#             # Now, let's do one pass through the model\n",
    "#             pred_hr_tmin1 = pq_diff_model(hr_img, lr_imgs, t)\n",
    "#             if loss_function == 'mse':\n",
    "#                 loss = mse(pred_hr_tmin1, \n",
    "#                            hr_tmin1)\n",
    "#             else:\n",
    "#                 loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                        hr_tmin1.expand(3,-1,-1))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             del lr_imgs, hr_img, t, hr_t, hr_tmin1, pred_hr_tmin1\n",
    "#             running_loss += loss.item()\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     train_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     train_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Training Loss: {avg_running_loss:.4f}')\n",
    "#             \n",
    "#         # Testing\n",
    "#         pq_diff_model.eval()\n",
    "#         pq_diff_model.calc_test_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(test_data)):\n",
    "#             with torch.no_grad():\n",
    "#                 lr_imgs, hr_img = get_sample(test_data, i)\n",
    "#                 # random t-step to predict\n",
    "#                 t = torch.randint(low=0, high=50, size=(1,)).to('cpu')\n",
    "#                 # hr_img after t steps of noise addition\n",
    "#                 hr_t = pq_diff_model.add_noise(hr_img, t)\n",
    "#                 # hr_img after t-1 steps of noise addition\n",
    "#                 # This is what we want the model to predict (bc we want the reverse process)\n",
    "#                 hr_tmin1 = pq_diff_model.add_noise(hr_img, t-1)\n",
    "#                 # Now, let's do one pass through the model\n",
    "#                 pred_hr_tmin1 = pq_diff_model(hr_t, lr_imgs, t)\n",
    "#                 if loss_function == 'mse':\n",
    "#                     loss = mse(pred_hr_tmin1, hr_tmin1)\n",
    "#                 else:\n",
    "#                     loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                            hr_tmin1.expand(3,-1,-1))\n",
    "#                 running_loss += loss.item()\n",
    "#                 del lr_imgs, hr_img, t, hr_t, hr_tmin1, pred_hr_tmin1\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     test_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     test_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Testing Loss: {avg_running_loss:.4f}')\n",
    "#         \n",
    "#                 # Capture results\n",
    "#                 if avg_running_loss < best_val_loss:\n",
    "#                     # print(avg_running_loss, best_val_loss)\n",
    "#                     best_val_loss = avg_running_loss\n",
    "#                     save_dict = dict()\n",
    "#                     save_dict[0] = pq_diff_model.state_dict()\n",
    "#                     if loss_function == 'mse':\n",
    "#                         save_dict[1] = train_mse_loss\n",
    "#                         save_dict[2] = test_mse_loss\n",
    "#                     else:\n",
    "#                         save_dict[1] = train_pq_loss\n",
    "#                         save_dict[2] = test_pq_loss\n",
    "#                     save_dict[3] = best_val_loss\n",
    "#                     torch.save(save_dict, path)\n",
    "#             \n",
    "#         # Calculate epoch training/testing time\n",
    "#         if epoch==0:\n",
    "#             prev_time = start_time\n",
    "#         else:\n",
    "#             prev_time = curr_time    \n",
    "#         curr_time = time.time()\n",
    "#         time_diff = (curr_time - prev_time) # in seconds\n",
    "#         minutes, seconds = divmod(time_diff, 60)\n",
    "#         minutes = int(minutes)\n",
    "#         seconds = int(seconds)\n",
    "#         \n",
    "#         print(f'Time:')\n",
    "#         print(f'{minutes} minutes:{seconds} seconds')\n",
    "#         print()\n",
    "# \n",
    "# # Plotting avg. training and testing loss for MSE-trained model\n",
    "# plt.plot(train_pq_loss)\n",
    "# plt.plot(test_pq_loss)\n",
    "# plt.title(\"Pereceptual Loss\")\n",
    "# plt.legend(['Train', 'Test'])\n",
    "# \n",
    "# ### Testing diffusion model code\n",
    "# \n",
    "# torch.cuda.empty_cache()\n",
    "# # Can be either 'mse' or 'pq'\n",
    "# loss_function = 'mse'\n",
    "# path = f'saved_models/diff_model_{loss_function}.pt'\n",
    "# # Initialize Model architecture\n",
    "# mse_diff_model = diffusion_vsr(s=torch.tensor(0.0008), \n",
    "#                            train_T=torch.tensor(1000), \n",
    "#                            infer_T=torch.tensor(50)).to(device)\n",
    "# if new_model:\n",
    "#     # Train/Test \n",
    "#     # Mean Square Error/Perceptual Quality\n",
    "#     train_mse_loss = []\n",
    "#     train_mse_loss = []\n",
    "#     test_mse_loss = []\n",
    "#     test_mse_loss = []\n",
    "#     best_val_loss = float('inf')\n",
    "# else:\n",
    "#     # Get dictionary of info\n",
    "#     old_model = torch.load(path, map_location=device)\n",
    "#     # load model with previous weights/parameters\n",
    "#     mse_diff_model.load_state_dict(old_model[0])\n",
    "#     # update previous lists of loss\n",
    "#     if loss_function == 'mse':\n",
    "#         train_mse_loss = old_model[1]\n",
    "#         test_mse_loss = old_model[2]\n",
    "#     else:\n",
    "#         train_pq_loss = old_model[1]\n",
    "#         test_pq_loss = old_model[2]\n",
    "#     best_val_loss = old_model[3]\n",
    "#     \n",
    "# if train:\n",
    "#     start_time = time.time()\n",
    "#     mse = nn.MSELoss()\n",
    "#     optimizer = torch.optim.Adam(params=mse_diff_model.parameters(),\n",
    "#                                  lr=learning_rate)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "#         # Training\n",
    "#         mse_diff_model.train()\n",
    "#         mse_diff_model.calc_train_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(train_data)):\n",
    "#             lr_imgs, hr_img = get_sample(train_data, i)\n",
    "#             # random t-step to predict\n",
    "#             t = torch.randint(low=0, high=1000, size=(1,)).to(device)\n",
    "#             # hr_img after t steps of noise addition\n",
    "#             hr_t = mse_diff_model.add_noise(hr_img, t)\n",
    "#             # hr_img after t-1 steps of noise addition\n",
    "#             # This is what we want the model to predict (bc we want the reverse process)\n",
    "#             hr_tmin1 = mse_diff_model.add_noise(hr_img, t-1)\n",
    "#             # Now, let's do one pass through the model\n",
    "#             pred_hr_tmin1 = mse_diff_model(hr_img, lr_imgs, t)\n",
    "#             if loss_function == 'mse':\n",
    "#                 loss = mse(pred_hr_tmin1, \n",
    "#                            hr_tmin1)\n",
    "#             else:\n",
    "#                 loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                        hr_tmin1.expand(3,-1,-1))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             running_loss += loss.item()\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     train_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     train_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Training Loss: {avg_running_loss:.4f}')\n",
    "#             \n",
    "#         # Testing\n",
    "#         mse_diff_model.eval()\n",
    "#         mse_diff_model.calc_test_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(test_data)):\n",
    "#             with torch.no_grad():\n",
    "#                 lr_imgs, hr_img = get_sample(test_data, i)\n",
    "#                 # random t-step to predict\n",
    "#                 t = torch.randint(low=0, high=50, size=(1,)).to(device)\n",
    "#                 # hr_img after t steps of noise addition\n",
    "#                 hr_t = mse_diff_model.add_noise(hr_img, t)\n",
    "#                 # hr_img after t-1 steps of noise addition\n",
    "#                 # This is what we want the model to predict (bc we want the reverse process)\n",
    "#                 hr_tmin1 = mse_diff_model.add_noise(hr_img, t-1)\n",
    "#                 # Now, let's do one pass through the model\n",
    "#                 pred_hr_tmin1 = mse_diff_model(hr_t, lr_imgs, t)\n",
    "#                 if loss_function == 'mse':\n",
    "#                     loss = mse(pred_hr_tmin1, hr_tmin1)\n",
    "#                 else:\n",
    "#                     loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                            hr_tmin1.expand(3,-1,-1))\n",
    "#                 running_loss += loss.item()\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     test_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     test_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Testing Loss: {avg_running_loss:.4f}')\n",
    "#         \n",
    "#                 # Capture results\n",
    "#                 if avg_running_loss < best_val_loss:\n",
    "#                     # print(avg_running_loss, best_val_loss)\n",
    "#                     best_val_loss = avg_running_loss\n",
    "#                     save_dict = dict()\n",
    "#                     save_dict[0] = mse_diff_model.state_dict()\n",
    "#                     if loss_function == 'mse':\n",
    "#                         save_dict[1] = train_mse_loss\n",
    "#                         save_dict[2] = test_mse_loss\n",
    "#                     else:\n",
    "#                         save_dict[1] = train_mse_loss\n",
    "#                         save_dict[2] = test_mse_loss\n",
    "#                     save_dict[3] = best_val_loss\n",
    "#                     torch.save(save_dict, path)\n",
    "#             \n",
    "#         # Calculate epoch training/testing time\n",
    "#         if epoch==0:\n",
    "#             prev_time = start_time\n",
    "#         else:\n",
    "#             prev_time = curr_time    \n",
    "#         curr_time = time.time()\n",
    "#         time_diff = (curr_time - prev_time) # in seconds\n",
    "#         minutes, seconds = divmod(time_diff, 60)\n",
    "#         minutes = int(minutes)\n",
    "#         seconds = int(seconds)\n",
    "#         \n",
    "#         print(f'Time:')\n",
    "#         print(f'{minutes} minutes:{seconds} seconds')\n",
    "#         print()\n",
    "#         \n",
    "# # Plotting avg. training and testing loss for MSE-trained model\n",
    "# plt.plot(train_mse_loss)\n",
    "# plt.plot(test_mse_loss)\n",
    "# plt.title(\"MSE Loss\")\n",
    "# plt.legend(['Train', 'Test'])"
   ],
   "id": "7db34393da7e6e0a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T23:26:44.426709Z",
     "start_time": "2024-04-28T23:26:44.425475Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29ef8b53f8d4e777",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
