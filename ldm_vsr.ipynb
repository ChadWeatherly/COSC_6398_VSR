{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6be0b271d4abd02",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Diffusion Model for Video Super Resolution\n",
    "\n",
    "Inspiration gathered from:\n",
    "\n",
    "https://github.com/CompVis/latent-diffusion\n",
    "\n",
    "https://ar5iv.labs.arxiv.org/html/2311.15908"
   ]
  },
  {
   "cell_type": "code",
   "id": "6840a1735dd2c511",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:39.293833Z",
     "start_time": "2024-04-17T04:00:39.290860Z"
    }
   },
   "source": [
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # provides functions that don't need to be in a computational graph, i.e. aren't part of a NN, usually for single-use\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
    "set('PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512')\n",
    "set('PYTORCH_ENABLE_MPS_FALLBACK=1')\n",
    "\n",
    "\"\"\"\n",
    "if matplotlib doesn't run, go into the envs/pytorch_vsr environment in anaconda3\n",
    "and delete all version of libiomp5md.dll , and it should work\n",
    "\"\"\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
    "# device = 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "1de92679892104e7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:39.304088Z",
     "start_time": "2024-04-17T04:00:39.301956Z"
    }
   },
   "source": [
    "torchvision.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "3783a106bfa2d3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:39.307149Z",
     "start_time": "2024-04-17T04:00:39.305050Z"
    }
   },
   "source": [
    "# # datasets with _sharp are the correct/ground truth images\n",
    "# # datasets with _blur_bicubic are those that have been blurred and\n",
    "# # downsampled using bicubic interpolation\n",
    "# datasets = ['train_sharp', 'train_blur_bicubic', 'val_sharp', 'val_blur_bicubic']\n",
    "# for set in datasets:\n",
    "#     print(set)\n",
    "#     if not os.path.isfile(f\"REDS/{set}.zip\"):\n",
    "#         # print(\"Downloading\")\n",
    "#         cmdlet = f\"python download_REDS.py --{set}\"\n",
    "#         print(cmdlet)\n",
    "#         os.system(cmdlet)\n",
    "# # if not already downloaded, this will download all datasets (takes a while)\n",
    "# \n",
    "# # Set up data into dataset and dataloader\n",
    "# # It assumes the project file structure as downloaded from above\n",
    "# # Built based on docs: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "# class REDS(Dataset):\n",
    "#     def __init__(self, train=True, device='cuda'):\n",
    "#         self.device = device\n",
    "#         self.type = 'train' if train else 'test' \n",
    "#         if self.type == 'train':\n",
    "#             self.hr_dir = \"REDS/train_sharp/train/train_sharp\"\n",
    "#             self.lr_dir = \"REDS/train_blur_bicubic/train/train_blur_bicubic/X4\"\n",
    "#         else:\n",
    "#             self.hr_dir = \"REDS/val_sharp/val/val_sharp\"\n",
    "#             self.lr_dir = \"REDS/val_blur_bicubic/val/val_blur_bicubic/X4\"\n",
    "#             \n",
    "#     def __len__(self):\n",
    "#         return len(os.listdir(self.hr_dir)) # training size = 240 videos, testing size = 30 videos\n",
    "#             \n",
    "#     def __getitem__(self, idx):\n",
    "#         # each return gives a single HR frame with 5 corresponding LR frames\n",
    "#         # the middle LR frame (frame 3) will be the blurred/downsampled version of the HR frame\n",
    "#         # the 5 sequential LR frames will be chosen randomly from the given idx-video\n",
    "#         \n",
    "#         # Getting video sequence folder name\n",
    "#         if idx < 10:\n",
    "#             video = '00' + str(idx)\n",
    "#         elif idx < 100:\n",
    "#             video = '0' + str(idx)\n",
    "#         else:\n",
    "#             video = str(idx)\n",
    "#         # Getting random sequence of 5 LR frames from the video    \n",
    "#         num_video_frames = len(os.listdir(f\"{self.hr_dir}/000\"))\n",
    "#         rand_frame_id = np.random.randint(2, num_video_frames - 2)\n",
    "#         lr_frame_idx = []\n",
    "#         for i in range(-2, 3):\n",
    "#             id_int = rand_frame_id + i\n",
    "#             if id_int < 10:\n",
    "#                 id_str = '0000000' + str(id_int)\n",
    "#             elif id_int < 100:\n",
    "#                 id_str = '000000' + str(id_int)\n",
    "#             else:\n",
    "#                 id_str = '00000' + str(id_int)\n",
    "#             lr_frame_idx.append(id_str)\n",
    "#         # Actually reading in the images\n",
    "#         hr_frame = torchvision.io.read_image(f\"{self.hr_dir}/{video}/{lr_frame_idx[2]}.png\").to(self.device)\n",
    "#         lr_frames = []\n",
    "#         for v in lr_frame_idx:\n",
    "#             lr_frame = torchvision.io.read_image(f\"{self.lr_dir}/{video}/{v}.png\").to(self.device)\n",
    "#             lr_frames.append(lr_frame)\n",
    "#         lr_frames = torch.stack(lr_frames).permute(1, 0, 2, 3)\n",
    "#         # hr_frame is of size 3x720x1280 (CxHxW)\n",
    "#         # lr_imgs of of size 5x3x180x320 (TxCxHxW)\n",
    "#         # where C=channel, T=time (video sequence)\n",
    "#         return torch.tensor(lr_frames).float(), hr_frame.float()"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "8859036c19a75c4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:39.476886Z",
     "start_time": "2024-04-17T04:00:39.319674Z"
    }
   },
   "source": [
    "# If using REDS\n",
    "# train_dataset = REDS(train=True, device=device)\n",
    "# test_dataset = REDS(train=False, device=device)\n",
    "\n",
    "# If using moving MNIST : http://www.cs.toronto.edu/~nitish/unsupervised_video/\n",
    "# This will download all the data\n",
    "data = torchvision.datasets.MovingMNIST(root='./', split=None,\n",
    "                                        split_ratio=10, download=True)\n",
    "train_data = data[0:8000].to('cpu')      # 80% for train\n",
    "test_data = data[8000:10001].to('cpu')    # 20% for test\n",
    "\n",
    "def transform_image(image):\n",
    "    # Performs downsampling and then blurring\n",
    "    image = torchvision.transforms.functional.resize(image, (32, 32))\n",
    "    gb = torchvision.transforms.GaussianBlur(kernel_size=(3,3))\n",
    "    image = gb(image)\n",
    "    return image\n",
    "    \n",
    "def get_sample(data, idx):\n",
    "    \"\"\"\n",
    "    Given a dataset (train/test) and a sample idx, a random sequence\n",
    "    of 5 LR frames is computed\n",
    "    \"\"\"\n",
    "    num_video_frames = data[idx].size()[0]\n",
    "    rand_frame_idx = np.random.randint(2, num_video_frames - 2)\n",
    "    # Get HR frame\n",
    "    hr_frame = data[idx][rand_frame_idx].to(device)\n",
    "    # Get LR frames\n",
    "    lr_frames = [data[idx][k] for k in range(rand_frame_idx-2, rand_frame_idx+3)]\n",
    "    lr_frames = [transform_image(frame) for frame in lr_frames]\n",
    "    lr_frames = torch.stack(lr_frames, dim=0).to(device) # permuted to have channel first\n",
    "    return lr_frames, hr_frame\n",
    "\n",
    "lr_frames, hr_frame = get_sample(data, 0)\n",
    "print('Comparing the 5 low-res images to the one high-res one')\n",
    "for f in lr_frames:\n",
    "    pil_fr = torchvision.transforms.ToPILImage()(f)\n",
    "    display(pil_fr)\n",
    "display(torchvision.transforms.ToPILImage()(hr_frame))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the 5 low-res images to the one high-res one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAA9klEQVR4nGNgGAKAEUOAg/kvE8O3/zA+C7oCjmlalxX/Jzz9j0sBo4iMGDOP2aY/uBR8T2X7yL8dYTOGgv+vOFhUBN/9RxeHGM/KysYuvejk468TOLCZwCph9Z+HxUDj8U+243+x6GcJvPjsTGvkg1Sxph382NzA6rR96yXmvCebv1lc/4nVBZwcLBwelwJYhS92cWBTwMrBIx91JIKDUXyJJhMWea64vgOvXnhxMDAwciHJw5kcgWFfBM5/kPzLwPD/2z9M/cy2d5+ezZCYNpkT3W9Q+u+FjkdnPjNc8MJmO8QPrCwMDIz8aWy4FECVEZAfBeQDAANNRQNcOGcoAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABDElEQVR4nO3SzU/CMBQA8Nd1OldhZFNHnRgTEhc8CN48+P/HgwcvGk0cOPAgQoZORrqPsnljHekuXrz4Tu3rr++9JgX4+0DVrXps6xn/nEVlpgr03rWTsofbEihbFVVNa7muLSSq5+kLa9F+odaCZJpTG5M9ldcAIO6g73gYb8D2DAhjjbOokLfYsdqnNAm/R2+ZFOyeDc7RfMnzWVBWEFtgwyIZPzqAIJW/olh5/kdD94eTtTCUAFTSbFpde3E/jKRgv02dk076fOfH4q3NSuteXRwa5mPwmoAUmJc3dD4yQyUHOVDiydgbu1aDhHKwenqPpl+sE1e/iLhDBYBprANWBwAAEIIc/uMX8QMbaVcLuPTCegAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABDklEQVR4nOXQwUvDMBQG8Jd2yWpptUPWimVgQdlhc04Ggv//RZgiXiqoiG7ITFtd51y31Tb1uASS3Tz5bsn78ZEvAH8+SDg1DhwEc5qwzVVNAO5lB6PXq+9MBXRcx00jvleC+OaNDExDBxX4RLkPOwZRAvAG/fbPE5+giQABQet5rkyo6LBcrV+mSsBotNdi00IvFQBZ3vnJsos/RpkcNDpnXfhqWc9UAUxnN0rKY/t989ciKOLbdBnYs4cF14t/gmHZth+w8C6VJuhN1/cCk16HM2lNtN87DYzDdDxOKikgRxe9arQoco3bCwmQhJNHrQ0OyEE5GdZoUmck44HYogLALs4i2DZIQ1v3/3R+AWiYWnYKtbC/AAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABK0lEQVR4nOWQS0/CQBSFZ9ra5zA1RtRErNSykBh1QWLc+tfduDE+SJSkkhALWkIBxYL2OXWhxI6ZWbn0rG5Ovjl3zgXgr4LlWdNJKmZRVgak0iw7h1pEBvcTLrBzupkJN2MukE/cMapXEeABsfuCbZVAWJRMoZyQof2Ws6aXH1EA0O2jZnUFUh5FJ/4tSXrDnAuEbU9Wus/UHai4bJ4jOIu4LQAAwuzxFYuCTMK370WQBnBj21CFUBG77ZCZMB/tHRvBaAu/37FXkCIfTn1Ui4LlT36tAGhdXJgntnvuF8wExdDMg1rl4TJYnpsGZKvZsHaTi2svZdaUrLPWKpCSOEwAG9ioVwadzNbwExvIp1cdryd8YPHHo1uoOlmkqmP2+xzgS5ocRwz7f+sTwNJp9PxFC9kAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAABI0lEQVR4nN3PS0vDQBAH8Nm8Ng+0j9hUK1rU1osIRQ/i9z8IIp6KhaKVFh9JkzbaJnGTsBsPBWtw15sX/6fZ3R+zMwB/HrQuaztVBAsvYCWgrMvmxYkG4+soEQFJxYqDgzsh8G9f8TnWZRCBuZTvFrqBhQCc3tlxNpLK4PsRIU3KlpmwQ+HdAEnHoRAwb1ppMZ+IZwBkpOQNfgPBgISgmqaqyMl7tLorTWxr+XzzsLsRZ0YwvP/ZgfkA+v7pAaGNbfeF8wUAAELpdEqqKFkIAPMiRo/opO/ygWxZW7WG/TEYJnzgtLt7LWdy1Z/x1gSo9y47MjXTOCz4QK8bs0e3k1b0mA/Ys0IentwmUb+2KgPVUrKYtm06WvLBKlgDkvMe/m8+AZLlaXX9yFS+AAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAABoklEQVR4nO2UsUsCURzHv0YiIrR0TgUOQp5IBB4NBVqTW5BSf0LS6hCEbuL/IOQiDk2K0JBjODVYTWlTZBDZw5bIanm/Z4NlQd55926L+0wHv9/383vv3rsDHBymEByy/L5n7yx/Ni8nKNE3Ed2eGXOqA93KrFHs5cPdBwDFbW7MXzZSAIBLKsutAE0AgM9j0GLmHWyG0bcjmAsCJ7pV4y14V3ZDUFaBw8fb6ZMmsDS+CEd6LSbvQU9XYLyFt1M8lFGK9JIX5gZN5pyO9YsmtrC+jI4twZoXdVuCLcOqyVPQx/gUAGBxAUDgWcXN+6Sya0o8vh2L4uoe4ZCrvmN9fYGaIEGCutkMG5L1fJhx4sSLCQUap7x1QUtQNzv6p9RooFoXJIsJZfSUIp61nv9BY4LZyaPJWdRG3FcTLCwfj6fbsvMDmlbokCBRlRudY5x4mxMnufkZasW0gqDBqyhKCRiPpYjTtVqhJ4m4xkRbkGA5IC3Ib13QHH0FUQAK8bR1gb/RraS/7rEgCQGgjJ+qvCEj+LWaO5sCqMr0HgcHB4d/wCe8JKM1tpWq8gAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:39.480573Z",
     "start_time": "2024-04-17T04:00:39.478010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "h_in = 32\n",
    "w_in = 32\n",
    "c_in = 1\n",
    "k = 3\n",
    "s = 1\n",
    "p = 1\n",
    "d = 1\n",
    "\n",
    "conv_h_out = ((h_in + (2*p) - (d*(k-1)) -1) / s) + 1\n",
    "conv_w_out = ((h_in + (2*p) - (d*(k-1)) -1) / s) + 1\n",
    "\n",
    "k = 2\n",
    "s = 2\n",
    "p = 0\n",
    "d = 1\n",
    "\n",
    "pool_h_out = ((conv_h_out + (2*p) - (d*(k-1)) -1) / s) + 1\n",
    "pool_w_out = ((conv_w_out + (2*p) - (d*(k-1)) -1) / s) + 1\n",
    "\n",
    "print(pool_h_out, pool_w_out)"
   ],
   "id": "e495d623189aab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0 16.0\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "566a961439deb8ba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:40.007351Z",
     "start_time": "2024-04-17T04:00:39.481382Z"
    }
   },
   "source": [
    "# Set up loss functions\n",
    "\n",
    "# perceptual_loss\n",
    "vgg = torchvision.models.vgg19(weights='VGG19_Weights.IMAGENET1K_V1').features # removes final classification layer as we don't need it\n",
    "vgg.to(device)\n",
    "vgg.eval() # sets the model to evaluation mode, to not update weights/parameters\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False # don't calculate gradients after forward passes, reduces computation\n",
    "    \n",
    "# A hook function can be used on any nn.module(), like any layer of a neural net\n",
    "# Depending on whether it's a backwards hook (backprop) or forward hook (forward pass),\n",
    "# the inputs and outputs of that nn.module can be accessed for that operation\n",
    "# It's like an event, that each time it happens, the inputs/outputs of that module are saved and then used by vgg_hook\n",
    "vgg_activations = {3:torch.tensor(0),\n",
    "                   8:torch.tensor(0),\n",
    "                   17:torch.tensor(0),\n",
    "                   26:torch.tensor(0),\n",
    "                   35:torch.tensor(0)}\n",
    "def vgg_hook(module, input, output):   \n",
    "    # Get activations at several layers\n",
    "    for layer in [3, 8, 17, 26, 35]: # each of the layers we want\n",
    "        if module == vgg[layer]: \n",
    "            vgg_activations[layer] = output\n",
    "    \n",
    "for layer in [3, 8, 17, 26, 35]:\n",
    "    vgg[layer].register_forward_hook(vgg_hook)\n",
    "\n",
    "def perceptual_loss(generated_img, target_img): # we want a lower value\n",
    "    # with torch.no_grad():\n",
    "    _ = vgg(generated_img)\n",
    "    generated_activations = vgg_activations.copy()\n",
    "    _ = vgg(target_img)\n",
    "    target_activations = vgg_activations.copy()\n",
    "    \n",
    "    # calculate F1 (mean absolute loss (MAE)) for each activation layer\n",
    "    mae_loss = []\n",
    "    for layer in [3, 8, 17, 26, 35]:\n",
    "        mae = F.l1_loss(generated_activations[layer],\n",
    "                        target_activations[layer])\n",
    "        mae_loss.append(mae)\n",
    "        \n",
    "    return sum(mae_loss)\n",
    "\n",
    "# Test if perceptual loss works\n",
    "lr_imgs1, hr_img1 = get_sample(train_data, 20)\n",
    "lr_imgs2, hr_img2 = get_sample(train_data, 30)\n",
    "\n",
    "print(f\"Differing video sequences: {perceptual_loss(hr_img1.expand(3,-1,-1).float(), hr_img2.expand(3,-1,-1).float())}\")\n",
    "print(f\"Same frame: {perceptual_loss(hr_img2.expand(3,-1,-1).float(), hr_img2.expand(3,-1,-1).float())}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differing video sequences: 170.6468963623047\n",
      "Same frame: 0.0\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T04:00:40.010501Z",
     "start_time": "2024-04-17T04:00:40.008659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters for training/testing\n",
    "new_model = False\n",
    "num_epochs = 35\n",
    "# pq batches take ~ 1 secs, so 1 epoch ~ 1.5 minutes\n",
    "# mse batches take ~ 1 secs, so 1 epoch ~ 1.5 minutes\n",
    "\n",
    "# To run an entire epoch through takes ~ 3 minutes for both models\n",
    "skip_graphs = False\n",
    "learning_rate = 0.000001\n",
    "batch_size = 100\n",
    "train = True           # if false, then the models will initialize with best weights (for inference/testing)"
   ],
   "id": "4799eeebab0107b2",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-17T04:00:40.011310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# Can be either 'mse' or 'pq'\n",
    "loss_function = 'pq'\n",
    "path = f'saved_models/recon_model_{loss_function}.pt'\n",
    "# Initialize Model architecture\n",
    "pq_recon_model = reconstructor(device=device).to(device)\n",
    "if new_model:\n",
    "    # Train/Test \n",
    "    # Mean Square Error/Perceptual Quality\n",
    "    train_mse_loss = []\n",
    "    train_pq_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_pq_loss = []\n",
    "    best_val_loss = float('inf')\n",
    "else:\n",
    "    # Get dictionary of info\n",
    "    old_model = torch.load(path, map_location=device)\n",
    "    # load model with previous weights/parameters\n",
    "    pq_recon_model.load_state_dict(old_model[0])\n",
    "    # update previous lists of loss\n",
    "    if loss_function == 'mse':\n",
    "        train_mse_loss = old_model[1]\n",
    "        test_mse_loss = old_model[2]\n",
    "    else:\n",
    "        train_pq_loss = old_model[1]\n",
    "        test_pq_loss = old_model[2]\n",
    "    best_val_loss = old_model[3]\n",
    "    \n",
    "if train:\n",
    "    start_time = time.time()\n",
    "    prev_batch_time = start_time\n",
    "    mse = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=pq_recon_model.parameters(),\n",
    "                                 lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        pq_recon_model.train()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(train_data)):\n",
    "            # Get data sample\n",
    "            lr_imgs, hr_img = get_sample(train_data, i)\n",
    "            lr_imgs = lr_imgs.float()\n",
    "            hr_img = hr_img.float().to(device)\n",
    "            # Do prediction\n",
    "            hr_pred = pq_recon_model(lr_imgs)\n",
    "            # calculate loss\n",
    "            if loss_function == 'mse':\n",
    "                loss = mse(hr_pred, \n",
    "                           hr_img)\n",
    "            else:\n",
    "                loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                       hr_img.expand(3,-1,-1))\n",
    "            # propagate loss through weights to find gradients\n",
    "            # and also adds gradients up\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            epoch_running_loss += loss.item()\n",
    "            del lr_imgs, hr_img, hr_pred\n",
    "            \n",
    "            if i % batch_size == 0 and i != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                avg_batch_loss = running_loss / batch_size\n",
    "                running_loss = 0\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                print(f'Batch: {int((i+1)/batch_size)} / {int(len(train_data)/batch_size)}')\n",
    "                print(f'Avg. Training Loss: {avg_batch_loss:.4f}')\n",
    "                # print(f'W-values: {pq_recon_model.w}')\n",
    "                # for name, param in pq_recon_model.named_parameters():\n",
    "                #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                #         print(param.data[0:5])\n",
    "                # Calculate batch training time   \n",
    "                curr_time = time.time()\n",
    "                time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                minutes, seconds = divmod(time_diff, 60)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'Training Time:')\n",
    "                print(f'{minutes} minutes:{seconds} seconds')\n",
    "                print()\n",
    "                prev_batch_time = curr_time\n",
    "                \n",
    "        avg_epoch_loss = epoch_running_loss / len(train_data)\n",
    "        if loss_function == 'mse':\n",
    "            train_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            train_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Training Loss: {avg_epoch_loss:.4f}')\n",
    "            \n",
    "        # Testing\n",
    "        pq_recon_model.eval()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(test_data)):\n",
    "            with torch.no_grad():\n",
    "                # Get data sample\n",
    "                lr_imgs, hr_img = get_sample(test_data, i)\n",
    "                hr_img = hr_img.float().to(device)\n",
    "                # Do prediction\n",
    "                hr_pred = pq_recon_model(lr_imgs)\n",
    "                hr_pred.requires_grad = True\n",
    "                # calculate loss\n",
    "                if loss_function == 'mse':\n",
    "                    loss = mse(hr_pred, \n",
    "                               hr_img)\n",
    "                else:\n",
    "                    loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                           hr_img.expand(3,-1,-1))\n",
    "                running_loss += loss.item()\n",
    "                epoch_running_loss += loss.item()\n",
    "                del lr_imgs, hr_img, hr_pred\n",
    "                \n",
    "                if i%batch_size == 0 and i != 0:\n",
    "                    avg_batch_loss = running_loss / batch_size\n",
    "                    running_loss = 0\n",
    "                    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                    print(f'Batch: {int((i+1)/batch_size)} / {int(len(test_data)/batch_size)}')\n",
    "                    print(f'Avg. Testing Loss: {avg_batch_loss:.4f}')\n",
    "                    # print(f'W-values: {pq_recon_model.w}')\n",
    "                    # for name, param in pq_recon_model.named_parameters():\n",
    "                    #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                    #         print(param.data[0:5])\n",
    "                    # Calculate batch training time   \n",
    "                    curr_time = time.time()\n",
    "                    time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                    minutes, seconds = divmod(time_diff, 60)\n",
    "                    minutes = int(minutes)\n",
    "                    seconds = int(seconds)\n",
    "                    print(f'Testing Time:')\n",
    "                    print(f'{minutes} minutes:{seconds} seconds')\n",
    "                    print()\n",
    "                    prev_batch_time = curr_time\n",
    "                    \n",
    "        avg_epoch_loss = epoch_running_loss / len(test_data)\n",
    "        if loss_function == 'mse':\n",
    "            test_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            test_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Testing Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # Capture results\n",
    "        if avg_epoch_loss < best_val_loss:\n",
    "            # print(avg_running_loss, best_val_loss)\n",
    "            best_val_loss = avg_epoch_loss\n",
    "            save_dict = dict()\n",
    "            save_dict[0] = pq_recon_model.state_dict()\n",
    "            if loss_function == 'mse':\n",
    "                save_dict[1] = train_mse_loss\n",
    "                save_dict[2] = test_mse_loss\n",
    "            else:\n",
    "                save_dict[1] = train_pq_loss\n",
    "                save_dict[2] = test_pq_loss\n",
    "            save_dict[3] = best_val_loss\n",
    "            torch.save(save_dict, path)\n",
    "            \n",
    "        # Calculate epoch training/testing time\n",
    "        if epoch==0:\n",
    "            curr_time = time.time()\n",
    "            prev_time = start_time\n",
    "        else:\n",
    "            prev_time = curr_time\n",
    "            curr_time = time.time()\n",
    "        time_diff = (curr_time - prev_time) # in seconds\n",
    "        minutes, seconds = divmod(time_diff, 60)\n",
    "        minutes = int(minutes)\n",
    "        seconds = int(seconds)\n",
    "        \n",
    "        print(f'Epoch Time:')\n",
    "        print(f'{minutes} minutes:{seconds} seconds')\n",
    "        print()\n",
    "        print(*\"====================\")\n",
    "        print()"
   ],
   "id": "8bcebbe8401c70a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "Batch: 1 / 80\n",
      "Avg. Training Loss: 110.7255\n",
      "Training Time:\n",
      "0 minutes:1 seconds\n",
      "\n",
      "Epoch 1/35\n",
      "Batch: 2 / 80\n",
      "Avg. Training Loss: 107.4833\n",
      "Training Time:\n",
      "0 minutes:1 seconds\n",
      "\n",
      "Epoch 1/35\n",
      "Batch: 3 / 80\n",
      "Avg. Training Loss: 109.6489\n",
      "Training Time:\n",
      "0 minutes:1 seconds\n",
      "\n",
      "Epoch 1/35\n",
      "Batch: 4 / 80\n",
      "Avg. Training Loss: 107.4358\n",
      "Training Time:\n",
      "0 minutes:1 seconds\n",
      "\n",
      "Epoch 1/35\n",
      "Batch: 5 / 80\n",
      "Avg. Training Loss: 108.4372\n",
      "Training Time:\n",
      "0 minutes:1 seconds\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if not skip_graphs:\n",
    "    # Plotting avg. training and testing loss for PQ-trained model\n",
    "    plt.plot(train_pq_loss)\n",
    "    plt.plot(test_pq_loss)\n",
    "    plt.title(\"Pereceptual Loss\")\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    \n",
    "    lr_imgs, hr_img = get_sample(test_data, 100)\n",
    "    hr_pred = pq_recon_model(lr_imgs)\n",
    "    \n",
    "    # mse_loss = mse(hr_pred, hr_img)\n",
    "    # perceptual_loss = perceptual_loss(hr_pred, hr_img)\n",
    "    # print(f'MSE Loss: {mse_loss:.4f}')\n",
    "    # print(f'Perceptual Loss: {perceptual_loss:.4f}')\n",
    "    \n",
    "    display(torchvision.transforms.ToPILImage()(hr_img))\n",
    "    display(torchvision.transforms.ToPILImage()(hr_pred))"
   ],
   "id": "c647af77cc73aacd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# Can be either 'mse' or 'pq'\n",
    "loss_function = 'mse'\n",
    "path = f'saved_models/recon_model_{loss_function}.pt'\n",
    "# Initialize Model architecture\n",
    "mse_recon_model = reconstructor(device=device).to(device)\n",
    "if new_model:\n",
    "    # Train/Test \n",
    "    # Mean Square Error/Perceptual Quality\n",
    "    train_mse_loss = []\n",
    "    train_pq_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_pq_loss = []\n",
    "    best_val_loss = float('inf')\n",
    "else:\n",
    "    # Get dictionary of info\n",
    "    old_model = torch.load(path, map_location=device)\n",
    "    # load model with previous weights/parameters\n",
    "    mse_recon_model.load_state_dict(old_model[0])\n",
    "    # update previous lists of loss\n",
    "    if loss_function == 'mse':\n",
    "        train_mse_loss = old_model[1]\n",
    "        test_mse_loss = old_model[2]\n",
    "    else:\n",
    "        train_pq_loss = old_model[1]\n",
    "        test_pq_loss = old_model[2]\n",
    "    best_val_loss = old_model[3]\n",
    "    \n",
    "if train:\n",
    "    start_time = time.time()\n",
    "    prev_batch_time = start_time\n",
    "    mse = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=mse_recon_model.parameters(),\n",
    "                                 lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        mse_recon_model.train()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(train_data)):\n",
    "            # Get data sample\n",
    "            lr_imgs, hr_img = get_sample(train_data, i)\n",
    "            hr_img = hr_img.float().to(device)\n",
    "            # Do prediction\n",
    "            hr_pred = mse_recon_model(lr_imgs)\n",
    "            # calculate loss\n",
    "            if loss_function == 'mse':\n",
    "                loss = mse(hr_pred, \n",
    "                           hr_img)\n",
    "            else:\n",
    "                loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                       hr_img.expand(3,-1,-1))\n",
    "            # propagate loss through weights to find gradients\n",
    "            # and also adds gradients up\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            epoch_running_loss += loss.item()\n",
    "            del lr_imgs, hr_img, hr_pred\n",
    "            \n",
    "            if i % batch_size == 0 and i != 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                avg_batch_loss = running_loss / batch_size\n",
    "                running_loss = 0\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                print(f'Batch: {int((i+1)/batch_size)} / {int(len(train_data)/batch_size)}')\n",
    "                print(f'Avg. Training Loss: {avg_batch_loss:.4f}')\n",
    "                # print(f'W-values: {mse_recon_model.w}')\n",
    "                # for name, param in mse_recon_model.named_parameters():\n",
    "                #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                #         print(param.data[0:5])\n",
    "                # Calculate batch training time   \n",
    "                curr_time = time.time()\n",
    "                time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                minutes, seconds = divmod(time_diff, 60)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'Training Time:')\n",
    "                print(f'{minutes} minutes:{seconds} seconds')\n",
    "                print()\n",
    "                prev_batch_time = curr_time\n",
    "                \n",
    "        avg_epoch_loss = epoch_running_loss / len(train_data)\n",
    "        if loss_function == 'mse':\n",
    "            train_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            train_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Training Loss: {avg_epoch_loss:.4f}')\n",
    "            \n",
    "        # Testing\n",
    "        mse_recon_model.eval()\n",
    "        running_loss = 0\n",
    "        epoch_running_loss = 0\n",
    "        for i in range(len(test_data)):\n",
    "            with torch.no_grad():\n",
    "                # Get data sample\n",
    "                lr_imgs, hr_img = get_sample(test_data, i)\n",
    "                hr_img = hr_img.float().to(device)\n",
    "                # Do prediction\n",
    "                hr_pred = mse_recon_model(lr_imgs)\n",
    "                hr_pred.requires_grad = True\n",
    "                # calculate loss\n",
    "                if loss_function == 'mse':\n",
    "                    loss = mse(hr_pred, \n",
    "                               hr_img)\n",
    "                else:\n",
    "                    loss = perceptual_loss(hr_pred.expand(3,-1,-1), \n",
    "                                           hr_img.expand(3,-1,-1))\n",
    "                running_loss += loss.item()\n",
    "                epoch_running_loss += loss.item()\n",
    "                del lr_imgs, hr_img, hr_pred\n",
    "                \n",
    "                if i%batch_size == 0 and i != 0:\n",
    "                    avg_batch_loss = running_loss / batch_size\n",
    "                    running_loss = 0\n",
    "                    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                    print(f'Batch: {int((i+1)/batch_size)} / {int(len(test_data)/batch_size)}')\n",
    "                    print(f'Avg. Testing Loss: {avg_batch_loss:.4f}')\n",
    "                    # print(f'W-values: {mse_recon_model.w}')\n",
    "                    # for name, param in mse_recon_model.named_parameters():\n",
    "                    #     if param.requires_grad and name=='lr.conv3.bias':\n",
    "                    #         print(param.data[0:5])\n",
    "                    # Calculate batch training time   \n",
    "                    curr_time = time.time()\n",
    "                    time_diff = (curr_time - prev_batch_time) # in seconds\n",
    "                    minutes, seconds = divmod(time_diff, 60)\n",
    "                    minutes = int(minutes)\n",
    "                    seconds = int(seconds)\n",
    "                    print(f'Testing Time:')\n",
    "                    print(f'{minutes} minutes:{seconds} seconds')\n",
    "                    print()\n",
    "                    prev_batch_time = curr_time\n",
    "                    \n",
    "        avg_epoch_loss = epoch_running_loss / len(test_data)\n",
    "        if loss_function == 'mse':\n",
    "            test_mse_loss.append(avg_epoch_loss)\n",
    "        else:\n",
    "            test_pq_loss.append(avg_epoch_loss)\n",
    "        print(f'Epoch Avg. Testing Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # Capture results\n",
    "        if avg_epoch_loss < best_val_loss:\n",
    "            # print(avg_running_loss, best_val_loss)\n",
    "            best_val_loss = avg_epoch_loss\n",
    "            save_dict = dict()\n",
    "            save_dict[0] = mse_recon_model.state_dict()\n",
    "            if loss_function == 'mse':\n",
    "                save_dict[1] = train_mse_loss\n",
    "                save_dict[2] = test_mse_loss\n",
    "            else:\n",
    "                save_dict[1] = train_pq_loss\n",
    "                save_dict[2] = test_pq_loss\n",
    "            save_dict[3] = best_val_loss\n",
    "            torch.save(save_dict, path)\n",
    "            \n",
    "        # Calculate epoch training/testing time\n",
    "        if epoch==0:\n",
    "            curr_time = time.time()\n",
    "            prev_time = start_time\n",
    "        else:\n",
    "            prev_time = curr_time\n",
    "            curr_time = time.time()\n",
    "        time_diff = (curr_time - prev_time) # in seconds\n",
    "        minutes, seconds = divmod(time_diff, 60)\n",
    "        minutes = int(minutes)\n",
    "        seconds = int(seconds)\n",
    "        \n",
    "        print(f'Epoch Time:')\n",
    "        print(f'{minutes} minutes:{seconds} seconds')\n",
    "        print()\n",
    "        print(*\"====================\")\n",
    "        print()"
   ],
   "id": "3825108fab352e76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if not skip_graphs:\n",
    "    # Plotting avg. training and testing loss for MSE-trained model\n",
    "    plt.plot(train_mse_loss)\n",
    "    plt.plot(test_mse_loss)\n",
    "    plt.title(\"MSE Loss\")\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    \n",
    "    lr_imgs, hr_img = get_sample(test_data, 25)\n",
    "    hr_pred = mse_recon_model(lr_imgs)\n",
    "    \n",
    "    # mse_loss = mse(hr_pred, hr_img)\n",
    "    # perceptual_loss = perceptual_loss(hr_pred, hr_img)\n",
    "    # print(f'MSE Loss: {mse_loss:.4f}')\n",
    "    # print(f'Perceptual Loss: {perceptual_loss:.4f}')\n",
    "    \n",
    "    display(torchvision.transforms.ToPILImage()(hr_img))\n",
    "    display(torchvision.transforms.ToPILImage()(hr_pred))"
   ],
   "id": "6d645f1db2480780",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "data[20].shape",
   "id": "8aacfba101cb6d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Show how predictions varied\n",
    "pq_recon_model.eval()\n",
    "mse_recon_model.eval()\n",
    "\n",
    "fig, axes = plt.subplots(5, 3)\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        axes[i,j].axis('off')\n",
    "axes[0,0].title.set_text('Ground Truth')\n",
    "axes[0,1].title.set_text('PQ Predicted')\n",
    "axes[0,2].title.set_text('MSE Predicted')\n",
    "for k in range(5): # Random inference values\n",
    "    with torch.no_grad():\n",
    "        lr_imgs, hr_img = get_sample(data, k)\n",
    "        hr_img = hr_img.squeeze().to('cpu').numpy()\n",
    "        hr_pred_pq = pq_recon_model(lr_imgs)\n",
    "        hr_pred_pq = hr_pred_pq.squeeze().to('cpu').numpy()\n",
    "        hr_pred_mse = mse_recon_model(lr_imgs)\n",
    "        hr_pred_mse = hr_pred_mse.squeeze().to('cpu').numpy()\n",
    "        axes[k,0].imshow(hr_img)\n",
    "        axes[k,1].imshow(hr_pred_pq)\n",
    "        axes[k,2].imshow(hr_pred_mse)\n",
    "        \n",
    "plt.savefig('report/figures/predictions.png')\n",
    "plt.show()"
   ],
   "id": "cbbe22d309c71640",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "axes",
   "id": "802b6e3043395ad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "# Create GIFs",
   "id": "cfe0229bc2dc69dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if not skip_graphs:\n",
    "    idx = np.random.randint(0, 10000)\n",
    "    \n",
    "    lr_frames, hr_frame = get_sample(data, idx)\n",
    "    print('Comparing the 5 low-res images to the one high-res one')\n",
    "    for j in range(len(lr_frames)):\n",
    "        f = lr_frames[j]\n",
    "        pil_fr = torchvision.transforms.ToPILImage()(f)\n",
    "        pil_fr.save(f'report/figures/Samples/{idx}_{j}_lr.png')\n",
    "        display(pil_fr)\n",
    "    pil_hr = torchvision.transforms.ToPILImage()(hr_frame)\n",
    "    pil_hr.save(f'report/figures/Samples/{idx}_hr.png')\n",
    "    display(pil_hr)"
   ],
   "id": "fe98de09f7cc2882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# # torch.cuda.empty_cache()\n",
    "# # Can be either 'mse' or 'pq'\n",
    "# loss_function = 'pq'\n",
    "# path = f'saved_models/diff_model_{loss_function}.pt'\n",
    "# # Initialize Model architecture\n",
    "# pq_diff_model = diffusion_vsr(s=torch.tensor(0.0008), \n",
    "#                            train_T=torch.tensor(1000), \n",
    "#                            infer_T=torch.tensor(1000),\n",
    "#                               device=device).to(device)\n",
    "# if new_model:\n",
    "#     # Train/Test \n",
    "#     # Mean Square Error/Perceptual Quality\n",
    "#     train_mse_loss = []\n",
    "#     train_pq_loss = []\n",
    "#     test_mse_loss = []\n",
    "#     test_pq_loss = []\n",
    "#     best_val_loss = float('inf')\n",
    "# else:\n",
    "#     # Get dictionary of info\n",
    "#     old_model = torch.load(path, map_location=device)\n",
    "#     # load model with previous weights/parameters\n",
    "#     pq_diff_model.load_state_dict(old_model[0])\n",
    "#     # update previous lists of loss\n",
    "#     if loss_function == 'mse':\n",
    "#         train_mse_loss = old_model[1]\n",
    "#         test_mse_loss = old_model[2]\n",
    "#     else:\n",
    "#         train_pq_loss = old_model[1]\n",
    "#         test_pq_loss = old_model[2]\n",
    "#     best_val_loss = old_model[3]\n",
    "#     \n",
    "# if train:\n",
    "#     start_time = time.time()\n",
    "#     mse = nn.MSELoss()\n",
    "#     optimizer = torch.optim.Adam(params=pq_diff_model.parameters(),\n",
    "#                                  lr=learning_rate)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "#         # Training\n",
    "#         pq_diff_model.train()\n",
    "#         pq_diff_model.calc_train_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(train_data)):\n",
    "#             lr_imgs, hr_img = get_sample(train_data, i)\n",
    "#             # random t-step to predict\n",
    "#             t = torch.randint(low=0, high=1000, size=(1,)).to(device)\n",
    "#             # hr_img after t steps of noise addition\n",
    "#             hr_t = pq_diff_model.add_noise(hr_img, t)\n",
    "#             # hr_img after t-1 steps of noise addition\n",
    "#             # This is what we want the model to predict (bc we want the reverse process)\n",
    "#             hr_tmin1 = pq_diff_model.add_noise(hr_img, t-1)\n",
    "#             # Now, let's do one pass through the model\n",
    "#             pred_hr_tmin1 = pq_diff_model(hr_img, lr_imgs, t)\n",
    "#             if loss_function == 'mse':\n",
    "#                 loss = mse(pred_hr_tmin1, \n",
    "#                            hr_tmin1)\n",
    "#             else:\n",
    "#                 loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                        hr_tmin1.expand(3,-1,-1))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             del lr_imgs, hr_img, t, hr_t, hr_tmin1, pred_hr_tmin1\n",
    "#             running_loss += loss.item()\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     train_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     train_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Training Loss: {avg_running_loss:.4f}')\n",
    "#             \n",
    "#         # Testing\n",
    "#         pq_diff_model.eval()\n",
    "#         pq_diff_model.calc_test_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(test_data)):\n",
    "#             with torch.no_grad():\n",
    "#                 lr_imgs, hr_img = get_sample(test_data, i)\n",
    "#                 # random t-step to predict\n",
    "#                 t = torch.randint(low=0, high=50, size=(1,)).to('cpu')\n",
    "#                 # hr_img after t steps of noise addition\n",
    "#                 hr_t = pq_diff_model.add_noise(hr_img, t)\n",
    "#                 # hr_img after t-1 steps of noise addition\n",
    "#                 # This is what we want the model to predict (bc we want the reverse process)\n",
    "#                 hr_tmin1 = pq_diff_model.add_noise(hr_img, t-1)\n",
    "#                 # Now, let's do one pass through the model\n",
    "#                 pred_hr_tmin1 = pq_diff_model(hr_t, lr_imgs, t)\n",
    "#                 if loss_function == 'mse':\n",
    "#                     loss = mse(pred_hr_tmin1, hr_tmin1)\n",
    "#                 else:\n",
    "#                     loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                            hr_tmin1.expand(3,-1,-1))\n",
    "#                 running_loss += loss.item()\n",
    "#                 del lr_imgs, hr_img, t, hr_t, hr_tmin1, pred_hr_tmin1\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     test_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     test_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Testing Loss: {avg_running_loss:.4f}')\n",
    "#         \n",
    "#                 # Capture results\n",
    "#                 if avg_running_loss < best_val_loss:\n",
    "#                     # print(avg_running_loss, best_val_loss)\n",
    "#                     best_val_loss = avg_running_loss\n",
    "#                     save_dict = dict()\n",
    "#                     save_dict[0] = pq_diff_model.state_dict()\n",
    "#                     if loss_function == 'mse':\n",
    "#                         save_dict[1] = train_mse_loss\n",
    "#                         save_dict[2] = test_mse_loss\n",
    "#                     else:\n",
    "#                         save_dict[1] = train_pq_loss\n",
    "#                         save_dict[2] = test_pq_loss\n",
    "#                     save_dict[3] = best_val_loss\n",
    "#                     torch.save(save_dict, path)\n",
    "#             \n",
    "#         # Calculate epoch training/testing time\n",
    "#         if epoch==0:\n",
    "#             prev_time = start_time\n",
    "#         else:\n",
    "#             prev_time = curr_time    \n",
    "#         curr_time = time.time()\n",
    "#         time_diff = (curr_time - prev_time) # in seconds\n",
    "#         minutes, seconds = divmod(time_diff, 60)\n",
    "#         minutes = int(minutes)\n",
    "#         seconds = int(seconds)\n",
    "#         \n",
    "#         print(f'Time:')\n",
    "#         print(f'{minutes} minutes:{seconds} seconds')\n",
    "#         print()\n",
    "# \n",
    "# # Plotting avg. training and testing loss for MSE-trained model\n",
    "# plt.plot(train_pq_loss)\n",
    "# plt.plot(test_pq_loss)\n",
    "# plt.title(\"Pereceptual Loss\")\n",
    "# plt.legend(['Train', 'Test'])\n",
    "# \n",
    "# ### Testing diffusion model code\n",
    "# \n",
    "# torch.cuda.empty_cache()\n",
    "# # Can be either 'mse' or 'pq'\n",
    "# loss_function = 'mse'\n",
    "# path = f'saved_models/diff_model_{loss_function}.pt'\n",
    "# # Initialize Model architecture\n",
    "# mse_diff_model = diffusion_vsr(s=torch.tensor(0.0008), \n",
    "#                            train_T=torch.tensor(1000), \n",
    "#                            infer_T=torch.tensor(50)).to(device)\n",
    "# if new_model:\n",
    "#     # Train/Test \n",
    "#     # Mean Square Error/Perceptual Quality\n",
    "#     train_mse_loss = []\n",
    "#     train_mse_loss = []\n",
    "#     test_mse_loss = []\n",
    "#     test_mse_loss = []\n",
    "#     best_val_loss = float('inf')\n",
    "# else:\n",
    "#     # Get dictionary of info\n",
    "#     old_model = torch.load(path, map_location=device)\n",
    "#     # load model with previous weights/parameters\n",
    "#     mse_diff_model.load_state_dict(old_model[0])\n",
    "#     # update previous lists of loss\n",
    "#     if loss_function == 'mse':\n",
    "#         train_mse_loss = old_model[1]\n",
    "#         test_mse_loss = old_model[2]\n",
    "#     else:\n",
    "#         train_pq_loss = old_model[1]\n",
    "#         test_pq_loss = old_model[2]\n",
    "#     best_val_loss = old_model[3]\n",
    "#     \n",
    "# if train:\n",
    "#     start_time = time.time()\n",
    "#     mse = nn.MSELoss()\n",
    "#     optimizer = torch.optim.Adam(params=mse_diff_model.parameters(),\n",
    "#                                  lr=learning_rate)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "#         # Training\n",
    "#         mse_diff_model.train()\n",
    "#         mse_diff_model.calc_train_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(train_data)):\n",
    "#             lr_imgs, hr_img = get_sample(train_data, i)\n",
    "#             # random t-step to predict\n",
    "#             t = torch.randint(low=0, high=1000, size=(1,)).to(device)\n",
    "#             # hr_img after t steps of noise addition\n",
    "#             hr_t = mse_diff_model.add_noise(hr_img, t)\n",
    "#             # hr_img after t-1 steps of noise addition\n",
    "#             # This is what we want the model to predict (bc we want the reverse process)\n",
    "#             hr_tmin1 = mse_diff_model.add_noise(hr_img, t-1)\n",
    "#             # Now, let's do one pass through the model\n",
    "#             pred_hr_tmin1 = mse_diff_model(hr_img, lr_imgs, t)\n",
    "#             if loss_function == 'mse':\n",
    "#                 loss = mse(pred_hr_tmin1, \n",
    "#                            hr_tmin1)\n",
    "#             else:\n",
    "#                 loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                        hr_tmin1.expand(3,-1,-1))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             running_loss += loss.item()\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     train_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     train_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Training Loss: {avg_running_loss:.4f}')\n",
    "#             \n",
    "#         # Testing\n",
    "#         mse_diff_model.eval()\n",
    "#         mse_diff_model.calc_test_steps()\n",
    "#         running_loss = 0\n",
    "#         for i in range(len(test_data)):\n",
    "#             with torch.no_grad():\n",
    "#                 lr_imgs, hr_img = get_sample(test_data, i)\n",
    "#                 # random t-step to predict\n",
    "#                 t = torch.randint(low=0, high=50, size=(1,)).to(device)\n",
    "#                 # hr_img after t steps of noise addition\n",
    "#                 hr_t = mse_diff_model.add_noise(hr_img, t)\n",
    "#                 # hr_img after t-1 steps of noise addition\n",
    "#                 # This is what we want the model to predict (bc we want the reverse process)\n",
    "#                 hr_tmin1 = mse_diff_model.add_noise(hr_img, t-1)\n",
    "#                 # Now, let's do one pass through the model\n",
    "#                 pred_hr_tmin1 = mse_diff_model(hr_t, lr_imgs, t)\n",
    "#                 if loss_function == 'mse':\n",
    "#                     loss = mse(pred_hr_tmin1, hr_tmin1)\n",
    "#                 else:\n",
    "#                     loss = perceptual_loss(pred_hr_tmin1.expand(3,-1,-1), \n",
    "#                                            hr_tmin1.expand(3,-1,-1))\n",
    "#                 running_loss += loss.item()\n",
    "#             \n",
    "#             if i%batch_size == 0 and i != 0:\n",
    "#                 avg_running_loss = running_loss / batch_size\n",
    "#                 running_loss = 0\n",
    "#                 if loss_function == 'mse':\n",
    "#                     test_mse_loss.append(avg_running_loss)\n",
    "#                 else:\n",
    "#                     test_pq_loss.append(avg_running_loss)\n",
    "#                 print(f'Batch Avg. Testing Loss: {avg_running_loss:.4f}')\n",
    "#         \n",
    "#                 # Capture results\n",
    "#                 if avg_running_loss < best_val_loss:\n",
    "#                     # print(avg_running_loss, best_val_loss)\n",
    "#                     best_val_loss = avg_running_loss\n",
    "#                     save_dict = dict()\n",
    "#                     save_dict[0] = mse_diff_model.state_dict()\n",
    "#                     if loss_function == 'mse':\n",
    "#                         save_dict[1] = train_mse_loss\n",
    "#                         save_dict[2] = test_mse_loss\n",
    "#                     else:\n",
    "#                         save_dict[1] = train_mse_loss\n",
    "#                         save_dict[2] = test_mse_loss\n",
    "#                     save_dict[3] = best_val_loss\n",
    "#                     torch.save(save_dict, path)\n",
    "#             \n",
    "#         # Calculate epoch training/testing time\n",
    "#         if epoch==0:\n",
    "#             prev_time = start_time\n",
    "#         else:\n",
    "#             prev_time = curr_time    \n",
    "#         curr_time = time.time()\n",
    "#         time_diff = (curr_time - prev_time) # in seconds\n",
    "#         minutes, seconds = divmod(time_diff, 60)\n",
    "#         minutes = int(minutes)\n",
    "#         seconds = int(seconds)\n",
    "#         \n",
    "#         print(f'Time:')\n",
    "#         print(f'{minutes} minutes:{seconds} seconds')\n",
    "#         print()\n",
    "#         \n",
    "# # Plotting avg. training and testing loss for MSE-trained model\n",
    "# plt.plot(train_mse_loss)\n",
    "# plt.plot(test_mse_loss)\n",
    "# plt.title(\"MSE Loss\")\n",
    "# plt.legend(['Train', 'Test'])"
   ],
   "id": "7db34393da7e6e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29ef8b53f8d4e777",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
